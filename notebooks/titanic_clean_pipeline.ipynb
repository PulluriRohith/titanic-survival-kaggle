{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12e61030",
   "metadata": {},
   "source": [
    "# Titanic – Clean End‑to‑End ML Workflow  \n",
    "  \n",
    "This notebook rebuilds the **entire** Titanic Kaggle pipeline from scratch:\n",
    "\n",
    "1. **Load data**  \n",
    "2. **Pre‑processing / feature engineering** (wrapped in a reusable class)  \n",
    "3. **Model training + 5‑fold cross‑validation**  \n",
    "4. **Fit final model and generate `submission.csv`**  \n",
    "\n",
    "All steps are fully reproducible and aligned between train & test – no missing columns, no dtype errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac5037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, warnings, os\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "TRAIN_CSV = 'train.csv'\n",
    "TEST_CSV  = 'test.csv'\n",
    "\n",
    "train_raw = pd.read_csv(TRAIN_CSV)\n",
    "test_raw  = pd.read_csv(TEST_CSV)\n",
    "\n",
    "print(f'train shape: {train_raw.shape} | test shape: {test_raw.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6152b91f",
   "metadata": {},
   "source": [
    "## Pre‑processing helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b8aa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicPreprocessor:\n",
    "    \"\"\"Fit once on train, apply to train & test, ensures aligned features.\"\"\"\n",
    "    def __init__(self, n_ticket_prefix=3):\n",
    "        self.age_median = None\n",
    "        self.age_bins = None\n",
    "        self.fare_median = None\n",
    "        self.fare_bins = None\n",
    "        self.top_prefixes = None\n",
    "        self.deck_categories = list('ABCDEF') + ['O','U']\n",
    "        self.embarked_modes = None\n",
    "        self.n_ticket_prefix = n_ticket_prefix\n",
    "        self.feature_columns_ = None\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    def _extract_title(self, s):\n",
    "        match = re.search(r',\\s*([^\\.]+)\\.', s)\n",
    "        return match.group(1).strip() if match else 'Rare'\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    def fit(self, df: pd.DataFrame):\n",
    "        # --- Age ---\n",
    "        self.age_median = df['Age'].median()\n",
    "        self.age_bins = [0,12,20,40,60,80, np.inf]\n",
    "\n",
    "        # --- Fare ---\n",
    "        self.fare_median = df['Fare'].median()\n",
    "        # 5‑quantile edges:\n",
    "        self.fare_bins  = list(df['Fare'].quantile([0, .2, .4, .6, .8, 1]))\n",
    "        self.fare_bins[-1] += 1  # ensure inclusive\n",
    "\n",
    "        # --- Ticket prefixes ---\n",
    "        prefixes = df['Ticket'].fillna('').str.split().str[:-1].str.join(' ')\n",
    "        self.top_prefixes = prefixes.value_counts().nlargest(self.n_ticket_prefix).index.tolist()\n",
    "\n",
    "        # --- Embarked mode ---\n",
    "        self.embarked_mode = df['Embarked'].mode().iloc[0]\n",
    "\n",
    "        # generate train feature matrix to lock column order\n",
    "        X = self.transform(df, fit_stage=True)\n",
    "        self.feature_columns_ = X.columns.tolist()\n",
    "        return self\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    def transform(self, df: pd.DataFrame, fit_stage=False):\n",
    "        out = pd.DataFrame(index=df.index)\n",
    "\n",
    "        # -------- Basic numeric/boolean ----------\n",
    "        out['Pclass'] = df['Pclass']\n",
    "        out['Sex']    = df['Sex'].map({'male':0,'female':1}).astype(int)\n",
    "        out['SibSp']  = df['SibSp']\n",
    "        out['Parch']  = df['Parch']\n",
    "\n",
    "        # -------- Family features -------------\n",
    "        fam_size = df['SibSp'] + df['Parch'] + 1\n",
    "        out['FamilySize'] = fam_size\n",
    "        out['IsAlone']    = (fam_size==1).astype(int)\n",
    "\n",
    "        # -------- Age -------------\n",
    "        age = df['Age'].fillna(self.age_median)\n",
    "        out['AgeBin'] = pd.cut(age, bins=self.age_bins, labels=False, right=False).astype(int)\n",
    "\n",
    "        # -------- Fare ------------\n",
    "        fare = df['Fare'].fillna(self.fare_median)\n",
    "        out['FareBin'] = pd.cut(fare, bins=self.fare_bins, labels=False, right=False).astype(int)\n",
    "\n",
    "        # -------- Cabin / Deck ------------\n",
    "        has_cabin = df['Cabin'].notna().astype(int)\n",
    "        deck = df['Cabin'].fillna('U').str[0]\n",
    "        deck = deck.replace({d:'O' for d,c in deck.value_counts().items() if c<10 and d not in ['U']})\n",
    "        out['HasCabin'] = has_cabin\n",
    "\n",
    "        deck_dummies = pd.get_dummies(deck).reindex(columns=self.deck_categories, fill_value=0)\n",
    "        deck_dummies.columns = [f'Deck_{c}' for c in deck_dummies.columns]\n",
    "        out = pd.concat([out, deck_dummies], axis=1)\n",
    "\n",
    "        # -------- Ticket features -----------\n",
    "        ticket = df['Ticket'].fillna('')\n",
    "        ticket_parts = ticket.str.split()\n",
    "        prefix = ticket_parts.str[:-1].str.join(' ')\n",
    "        number = ticket_parts.str[-1].where(ticket_parts.str[-1].str.isnumeric(), '0').astype(int)\n",
    "\n",
    "        out['HasTicketPrefix'] = (prefix!='').astype(int)\n",
    "        out['TicketNumber']    = number\n",
    "        # Ticket num bin\n",
    "        out['TicketNum_qbin']  = pd.qcut(number.rank(method='first'), 10, labels=False)\n",
    "        # Group size\n",
    "        group_size = df.groupby('Ticket')['PassengerId'].transform('count')\n",
    "        out['TicketGroupSize'] = group_size\n",
    "        out['IsGroupTicket']   = (group_size>1).astype(int)\n",
    "\n",
    "        # top‑N prefix one‑hots\n",
    "        prefix_reduced = prefix.where(prefix.isin(self.top_prefixes),'Other')\n",
    "        prefix_dummies = pd.get_dummies(prefix_reduced, prefix='TktPre')\n",
    "        out = pd.concat([out, prefix_dummies], axis=1)\n",
    "\n",
    "        # -------- Embarked -----------\n",
    "        embarked = df['Embarked'].fillna(self.embarked_mode)\n",
    "        embarked_dum = pd.get_dummies(embarked, prefix='Emb')\n",
    "        out = pd.concat([out, embarked_dum], axis=1)\n",
    "\n",
    "        # -------- Title (optional) ----------\n",
    "        title = df['Name'].apply(self._extract_title)\n",
    "        title_map = {t:i for i,t in enumerate(title.unique(),0)}\n",
    "        out['Title'] = title.map(title_map).astype(int)\n",
    "\n",
    "        # -------- Align columns order during inference -------------\n",
    "        if not fit_stage:\n",
    "            missing_cols = [c for c in self.feature_columns_ if c not in out.columns]\n",
    "            for c in missing_cols:\n",
    "                out[c] = 0\n",
    "            out = out[self.feature_columns_]\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f54882",
   "metadata": {},
   "source": [
    "## Fit pre‑processor on train and transform train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e51f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = TitanicPreprocessor()\n",
    "prep.fit(train_raw)\n",
    "\n",
    "X_train = prep.transform(train_raw)\n",
    "y_train = train_raw['Survived']\n",
    "X_test  = prep.transform(test_raw)\n",
    "\n",
    "print('Feature matrix shape:', X_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c745cfb",
   "metadata": {},
   "source": [
    "## 5‑fold Cross‑Validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20be9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = dict(\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8\n",
    ")\n",
    "model = XGBClassifier(**xgb_params)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "print(f'5‑fold CV accuracy: {scores.mean():.4f} ± {scores.std():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2374354b",
   "metadata": {},
   "source": [
    "## Train final model on full train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23979a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b82809",
   "metadata": {},
   "source": [
    "## Predict test set & build `submission.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d74a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw['Survived'] = model.predict(X_test).astype(int)\n",
    "submission = test_raw[['PassengerId','Survived']]\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print('Saved submission.csv with shape:', submission.shape)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
